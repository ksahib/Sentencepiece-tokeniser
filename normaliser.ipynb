{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize\n",
    "def normalize_text(text):\n",
    "    normalized = unicodedata.normalize('NFKC', text).lower()\n",
    "    #Note:\n",
    "    # r'() denotes raw string input, [,.!?;:] is the capturing group, r' \\1 ' means will replace the puncutations \n",
    "    # in the capturing group with itself wrapped in spaces\n",
    "    #/1 means the first punctuation mark encountered.\n",
    "    # Example: \"Hello, world!\" will be replaced with \"Hello , World !\", \n",
    "    # it matches the comma, /1 is now comma, and then it replaces it with r' \\1 ' which is \" , \"\n",
    "    normalized = re.sub(r'([,.!?;:])', r' \\1 ', normalized)\n",
    "    normalized = re.sub(r'\\s+', ' ', normalized)\n",
    "    # Replace spaces with the special token \"▁\"\n",
    "    normalized = normalized.replace(\" \", \"▁\")\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split text into sentences\n",
    "def split_into_sentences(text):\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract unique characters\n",
    "def extract_unique_characters(normalized_file):\n",
    "    unique_chars = set()\n",
    "    with open(normalized_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            unique_chars.update(line.strip()) \n",
    "    return sorted(list(unique_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_and_extract(input_file, output_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        sentences = split_into_sentences(infile.read())\n",
    "        for sentence in sentences:\n",
    "            normalized_sentence = normalize_text(sentence.strip())\n",
    "            outfile.write(normalized_sentence + '\\n')\n",
    "\n",
    "    vocab_chars = extract_unique_characters(output_file)\n",
    "    \n",
    "    special_tokens = [\"<unk>\", \"<s>\", \"</s>\", \"<pad>\"]\n",
    "    final_vocab = special_tokens + vocab_chars\n",
    "\n",
    "    token2idx = {token: idx for idx, token in enumerate(final_vocab)}\n",
    "    print(token2idx)\n",
    "    return token2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<unk>': 0, '<s>': 1, '</s>': 2, '<pad>': 3, '!': 4, ',': 5, '-': 6, '.': 7, ';': 8, '?': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'q': 26, 'r': 27, 's': 28, 't': 29, 'u': 30, 'v': 31, 'w': 32, 'x': 33, 'y': 34, 'z': 35, '“': 36, '”': 37, '▁': 38}\n"
     ]
    }
   ],
   "source": [
    "input_file = 'viterbi.txt'\n",
    "output_file = 'output.txt' \n",
    "\n",
    "token_dictionary = prepare_and_extract(input_file, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentencepiece",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
